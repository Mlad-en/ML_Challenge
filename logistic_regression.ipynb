{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    get_cross_validation_results, \n",
    "    TransactionDataset,\n",
    "    TuneHyperParams,\n",
    ")\n",
    "\n",
    "from constants import Resample, Columns, ModelConstants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, FunctionTransformer, Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TransactionDataset().get_training_test_split(resample=Resample.no_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining Column Transformations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_transform = FunctionTransformer(\n",
    "    func=np.log1p, inverse_func=np.expm1, check_inverse=False\n",
    ")\n",
    "\n",
    "log_and_ordinal_transforms = make_column_transformer(\n",
    "    (OneHotEncoder(), [Columns.CUSTOMER_TYPE]),\n",
    "    (OrdinalEncoder(), [Columns.SPECIFIC_HOLIDAY]),\n",
    "    (log_transform, make_column_selector(dtype_include=\"number\"))\n",
    ")\n",
    "\n",
    "norm_and_one_hot_transforms = make_column_transformer(\n",
    "    (OneHotEncoder(), [Columns.SPECIFIC_HOLIDAY, Columns.CUSTOMER_TYPE]),\n",
    "    (Normalizer(), make_column_selector(dtype_include=\"number\"))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regression_model = LogisticRegression(\n",
    "    random_state=ModelConstants.RANDOM_STATE,\n",
    "    max_iter=ModelConstants.MAX_ITERATIONS * 10,\n",
    "    warm_start=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining Model Pipelines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_and_ordinal_model_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"column_transformation\", log_and_ordinal_transforms),\n",
    "        (\"logistic_regression\", regression_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "norm_and_one_hot_model_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"column_transformation\", norm_and_one_hot_transforms),\n",
    "        (\"logistic_regression\", regression_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pca_and_log_ordinal_model_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"column_transformation\", log_and_ordinal_transforms),\n",
    "        (\"principal_components\", PCA()),\n",
    "        (\"logistic_regression\", regression_model)\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tuning Logistic Regression Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuning_params = {\n",
    "    \"logistic_regression__penalty\": [\"l1\", \"l2\"],\n",
    "    \"logistic_regression__solver\": [\"saga\", \"liblinear\"],\n",
    "    \"logistic_regression__C\": [0.1, 0.5, 1, 1.5, 2, 2.5, 3],\n",
    "    \"logistic_regression__class_weight\": [\n",
    "        \"balanced\",\n",
    "        {1: 0.55, 0: 0.45},\n",
    "        {1: 0.6, 0: 0.4},\n",
    "        {1: 0.65, 0: 0.35},\n",
    "        {1: 0.7, 0: 0.3},\n",
    "        {1: 0.75, 0: 0.25},\n",
    "        {1: 0.8, 0: 0.2},\n",
    "    ],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs_log_ordinal = (\n",
    "    TuneHyperParams()\n",
    "    .full_grid_search(\n",
    "     log_and_ordinal_model_pipeline,\n",
    "     tuning_params\n",
    "    )\n",
    "    .fit_model(\n",
    "        data.TRAINING.predictors,\n",
    "        data.TRAINING.outcome\n",
    "    )\n",
    "    .get_best_scores_and_params()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs_norm = (\n",
    "    TuneHyperParams()\n",
    "    .full_grid_search(\n",
    "     norm_and_one_hot_model_pipeline,\n",
    "     tuning_params\n",
    "    )\n",
    "    .fit_model(\n",
    "        data.TRAINING.predictors,\n",
    "        data.TRAINING.outcome\n",
    "    )\n",
    "    .get_best_scores_and_params()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_tuning = {\n",
    "    \"principal_components__n_components\": [3, 5, 7, 9, 11, 13, 15],\n",
    "    \"principal_components__whiten\": [True, False]\n",
    "}\n",
    "\n",
    "tuning_params = tuning_params | pca_tuning\n",
    "\n",
    "gs_pca = (\n",
    "    TuneHyperParams()\n",
    "    .full_grid_search(\n",
    "     pca_and_log_ordinal_model_pipeline,\n",
    "     tuning_params\n",
    "    )\n",
    "    .fit_model(\n",
    "        data.TRAINING.predictors,\n",
    "        data.TRAINING.outcome\n",
    "    )\n",
    "    .get_best_scores_and_params()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Refitting models after Grid Search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: 5.173618936538697\n",
      "score_time: 0.006949734687805176\n",
      "test_accuracy: 0.880068627615484\n",
      "test_balanced_accuracy: 0.8317220389462638\n",
      "test_f1: 0.6648300886446668\n",
      "The final Log model F1 score is: 0.6816568047337278\n"
     ]
    }
   ],
   "source": [
    "# {'logistic_regression__C': 1.5, 'logistic_regression__class_weight': {1: 0.8, 0: 0.2}, 'logistic_regression__penalty': 'l1', 'logistic_regression__solver': 'saga'}\n",
    "# Best parameter (CV score: 0.666):\n",
    "\n",
    "final_log_model = LogisticRegression(\n",
    "    C=1.5,\n",
    "    penalty=\"l1\",\n",
    "    solver=\"saga\",\n",
    "    class_weight={1: 0.8, 0: 0.2},\n",
    "    max_iter=ModelConstants.MAX_ITERATIONS * 10,\n",
    "    random_state=ModelConstants.RANDOM_STATE,\n",
    "    warm_start=True\n",
    ")\n",
    "\n",
    "final_log_model_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"column_transformation\", log_and_ordinal_transforms),\n",
    "        (\"logistic_regression\", final_log_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "get_cross_validation_results(\n",
    "    final_log_model_pipeline,\n",
    "    data.TRAINING.predictors,\n",
    "    data.TRAINING.outcome\n",
    ")\n",
    "\n",
    "final_log_model_pipeline.fit(data.TRAINING.predictors, data.TRAINING.outcome)\n",
    "\n",
    "predictions = final_log_model_pipeline.predict(data.TESTING.predictors)\n",
    "\n",
    "print(f\"The final Log model F1 score is: {f1_score(predictions, data.TESTING.outcome)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: 0.3940718412399292\n",
      "score_time: 0.007635927200317383\n",
      "test_accuracy: 0.878942836887763\n",
      "test_balanced_accuracy: 0.7779587663627822\n",
      "test_f1: 0.6198352238036511\n",
      "The final Norm model F1 score is: 0.6345381526104417\n"
     ]
    }
   ],
   "source": [
    "# {'logistic_regression__C': 1.5, 'logistic_regression__class_weight': 'balanced', 'logistic_regression__penalty': 'l1', 'logistic_regression__solver': 'liblinear'}\n",
    "# Best parameter (CV score: 0.617):\n",
    "\n",
    "final_norm_model = LogisticRegression(\n",
    "    C=1.5,\n",
    "    solver=\"liblinear\",\n",
    "    penalty=\"l1\",\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=ModelConstants.MAX_ITERATIONS * 10,\n",
    "    random_state=ModelConstants.RANDOM_STATE,\n",
    "    warm_start=True\n",
    ")\n",
    "\n",
    "final_norm_model_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"column_transformation\", norm_and_one_hot_transforms),\n",
    "        (\"logistic_regression\", final_norm_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "get_cross_validation_results(\n",
    "    final_norm_model_pipeline,\n",
    "    data.TRAINING.predictors,\n",
    "    data.TRAINING.outcome\n",
    ")\n",
    "\n",
    "final_norm_model_pipeline.fit(data.TRAINING.predictors, data.TRAINING.outcome)\n",
    "\n",
    "predictions = final_norm_model_pipeline.predict(data.TESTING.predictors)\n",
    "\n",
    "print(f\"The final Norm model F1 score is: {f1_score(predictions, data.TESTING.outcome)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: 0.048649048805236815\n",
      "score_time: 0.009540128707885741\n",
      "test_accuracy: 0.879147650049499\n",
      "test_balanced_accuracy: 0.8346525059058598\n",
      "test_f1: 0.6657237530635807\n",
      "The final PCA model F1 score is: 0.6814988290398126\n"
     ]
    }
   ],
   "source": [
    "# {'logistic_regression__C': 0.1, 'logistic_regression__class_weight': {1: 0.8, 0: 0.2}, 'logistic_regression__penalty': 'l1', 'logistic_regression__solver': 'liblinear', 'principal_components__n_components': 11, 'principal_components__whiten': False}\n",
    "# Best parameter (CV score: 0.667):\n",
    "\n",
    "final_log_pca_model = LogisticRegression(\n",
    "    C=0.1,\n",
    "    solver=\"liblinear\",\n",
    "    penalty=\"l1\",\n",
    "    class_weight={1: 0.8, 0: 0.2},\n",
    "    max_iter=ModelConstants.MAX_ITERATIONS * 10,\n",
    "    random_state=ModelConstants.RANDOM_STATE,\n",
    "    warm_start=True\n",
    ")\n",
    "\n",
    "final_pca_model_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"column_transformation\", log_and_ordinal_transforms),\n",
    "        (\"principal_components\", PCA(n_components=11, whiten=False)),\n",
    "        (\"logistic_regression\", final_log_pca_model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "get_cross_validation_results(\n",
    "    final_pca_model_pipeline,\n",
    "    data.TRAINING.predictors,\n",
    "    data.TRAINING.outcome\n",
    ")\n",
    "\n",
    "final_pca_model_pipeline.fit(data.TRAINING.predictors, data.TRAINING.outcome)\n",
    "\n",
    "predictions = final_pca_model_pipeline.predict(data.TESTING.predictors)\n",
    "\n",
    "print(f\"The final PCA model F1 score is: {f1_score(predictions, data.TESTING.outcome)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning-2iLmnJu8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
